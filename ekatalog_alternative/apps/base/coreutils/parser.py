from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as ec
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from time import sleep
import random
import re
from datetime import datetime
import logging
from pathlib import Path


# noinspection PyBroadException
class WildberriesScraper:
    def __init__(self, headless=True, log_level=logging.INFO):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫—Ä–∞–ø–µ—Ä–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏

        Args:
            headless (bool): –ó–∞–ø—É—Å–∫ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
            log_level: –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self.logger = None
        self.setup_logging(log_level)
        self.driver = None
        self.headless = headless
        self.user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36'
        ]

    def setup_logging(self, level):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            level=level,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('wildberries_scraper.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def create_driver(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –º–∞—Å–∫–∏—Ä–æ–≤–∫–æ–π"""
        options = webdriver.ChromeOptions()

        # –ë–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞—Å–∫–∏—Ä–æ–≤–∫–∏
        if self.headless:
            options.add_argument('--headless')

        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument('--disable-extensions')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--disable-web-security')
        options.add_argument('--allow-running-insecure-content')
        options.add_argument('--disable-features=VizDisplayCompositor')

        # –°–ª—É—á–∞–π–Ω—ã–π User-Agent
        user_agent = random.choice(self.user_agents)
        options.add_argument(f'--user-agent={user_agent}')

        # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
        prefs = {
            "profile.default_content_setting_values": {
                "notifications": 2,
                "media_stream": 2,
            }
        }
        options.add_experimental_option("prefs", prefs)

        try:
            self.driver = webdriver.Chrome(options=options)

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –º–∞—Å–∫–∏—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ JavaScript
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {"userAgent": user_agent})

            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –æ–∫–Ω–∞
            self.driver.set_window_size(1920, 1080)

            self.logger.info("–î—Ä–∞–π–≤–µ—Ä —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω")
            return True

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            return False

    def navigate_to_page(self, url, max_retries=3):
        """–ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        for attempt in range(max_retries):
            try:
                self.logger.info(f"–ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})")
                self.driver.get(url)

                # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                sleep(random.uniform(3, 7))

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
                if self.is_page_loaded():
                    self.logger.info("–°—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                    return True
                else:
                    self.logger.warning(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –ø–æ–ª–Ω–æ—Å—Ç—å—é, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}")

            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {e}")

            if attempt < max_retries - 1:
                sleep(random.uniform(5, 10))

        return False

    def is_page_loaded(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            page_source = self.driver.page_source

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            block_indicators = [
                "Access denied", "–î–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω", "403 Forbidden",
                "Captcha", "Robot Check", "–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"
            ]

            for indicator in block_indicators:
                if indicator in page_source:
                    self.logger.error(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞: {indicator}")
                    return False

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã
            if len(page_source) < 1000:
                self.logger.error("–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞")
                return False

            return True

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
            return False

    @staticmethod
    def cleaner(cleaning_str, option: int):
        """–§–∏–ª—å—Ç—Ä –ø–æ–ª–µ–π"""
        if not cleaning_str:
            return ""

        match option:
            case 1:
                """–û—á–∏—Å—Ç–∫–∞ —Ü–µ–Ω—ã –æ—Ç —Å–∏–º–≤–æ–ª–∞ —Ä—É–±–ª—è –∏ –ø—Ä–æ–±–µ–ª–æ–≤"""
                # –£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª —Ä—É–±–ª—è, –ø—Ä–æ–±–µ–ª—ã –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã —Å –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
                cleaned = re.sub(r'[‚ÇΩ\s]', '', cleaning_str)
                # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ —á–∏—Å–ª–∞—Ö –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É (–¥–ª—è –±–æ–ª—å—à–∏—Ö —á–∏—Å–µ–ª —Ç–∏–ø–∞ "27 880")
                cleaned = re.sub(r'(\d)\s+(\d)', r'\1\2', cleaned)
                return cleaned.strip()
            case 2:
                """–û—á–∏—Å—Ç–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ decimal —Ñ–æ—Ä–º–∞—Ç"""
                # –ò—â–µ–º —á–∏—Å–ª–æ —Å –≤–æ–∑–º–æ–∂–Ω–æ–π –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ —Ç–æ—á–∫–æ–π
                match = re.search(r'(\d+)[,.](\d+)', cleaning_str)
                if match:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ decimal —Ñ–æ—Ä–º–∞—Ç —Å —Ç–æ—á–∫–æ–π
                    return f"{match.group(1)}.{match.group(2)}"

                # –ò—â–µ–º —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ
                match = re.search(r'(\d+)', cleaning_str)
                if match:
                    return f"{match.group(1)}.0"

                return ""
            case 3:
                """–û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ç–∑—ã–≤–æ–≤ –æ—Ç —Å–ª–æ–≤ '–æ—Ü–µ–Ω–∫–∏', '–æ—Ü–µ–Ω–æ–∫' –∏ —Ç.–¥."""
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä
                cleaned = re.sub(r'\D', '', cleaning_str)
                return cleaned
            case _:
                raise ValueError("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–ø—Ü–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤")

    @staticmethod
    def extractor(element, selector, option: int, attribute=None):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏ –∑–Ω–∞—á–µ–Ω–∏—è –∞—Ç—Ç—Ä–∏–±—É—Ç–∞"""
        if not element or not selector:
            return None

        match option:
            case 1:
                """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞"""
                try:
                    elem = element.find_element(By.CSS_SELECTOR, selector)
                    text = elem.text.strip()
                    # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
                    if text.startswith("/ "):
                        text = text[2:]
                    return text
                except:
                    return ""
            case 2:
                """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç–∞"""
                try:
                    elem = element.find_element(By.CSS_SELECTOR, selector)
                    return elem.get_attribute(attribute) or ""
                except:
                    return ""
            case _:
                raise ValueError("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–ø—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ–∫–∞—Ç–æ—Ä–∞")

    def extract(self, product_element):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ–≤–∞—Ä–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        data = {}

        # –ú–∞–ø–ø–∏–Ω–≥ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
        selectors = {
            'wb_id': lambda: product_element.get_attribute("data-nm-id") or "",
            'title': lambda: self.extractor(product_element, ".product-card__name", 1),
            'price_discount': lambda: self.cleaner(self.extractor(product_element, ".price__lower-price", 1), 1),
            'price_original': lambda: self.cleaner(self.extractor(product_element, ".price__wrap del", 1), 1),
            'rating': lambda: self.cleaner(self.extractor(product_element, ".address-rate-mini", 1), 2),
            'reviews': lambda: self.cleaner(self.extractor(product_element, ".product-card__count", 1), 3),
            'link': lambda: self.extractor(product_element, ".product-card__link", 2, "href"),
            'photo': lambda: self.extractor(product_element, ".j-thumbnail", 2, "src")
        }

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        for key, extractor in selectors.items():
            try:
                data[key] = extractor()
            except Exception as e:
                self.logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è {key}: {e}")
                data[key] = ""

        return data

    def scrape(self, max_products):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤"""
        products_data = []

        try:
            products = self.driver.find_elements(By.CSS_SELECTOR, "article.product-card")
            total_products = min(len(products), max_products)

            self.logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ {total_products} —Ç–æ–≤–∞—Ä–æ–≤")

            for i, product in enumerate(products[:max_products]):
                try:
                    data = self.extract(product)
                    products_data.append(data)

                    # –ü—Ä–æ–≥—Ä–µ—Å—Å
                    if (i + 1) % 10 == 0:
                        self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {i + 1}")
                    else:
                        self.logger.debug(f"[{i + 1}] {data['title'][:40]}...")

                    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                    sleep(random.uniform(0.1, 0.5))

                except Exception as e:
                    self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–æ–≤–∞—Ä–∞ {i + 1}: {e}")
                    continue

            return products_data
        except Exception as e:
            self.logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
            return [], None

    def run(self, category_url, max_products=50):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∞–ø–µ—Ä–∞"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞
            if not self.create_driver():
                return False

            # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
            if not self.navigate_to_page(category_url):
                return False

            # –ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤
            products_data = self.scrape(max_products)

            self.logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products_data)}")

            return products_data

        except Exception as e:
            self.logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return False

        finally:
            self.cleanup()

    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if self.driver:
            try:
                self.driver.quit()
                self.logger.info("–î—Ä–∞–π–≤–µ—Ä –∑–∞–∫—Ä—ã—Ç")
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")


def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    laptops_url = "catalog/elektronika/noutbuki-pereferiya/noutbuki-ultrabuki"
    phones_url = "catalog/elektronika/smartfony-i-telefony/vse-smartfony"
    category_url = f"https://www.wildberries.ru/{laptops_url}"
    max_products = 2
    target_load = 2

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–µ—Ä–∞
    scraper = WildberriesScraper()

    try:
        success = scraper.run(
            category_url=category_url,
            max_products=max_products
        )

        if success:
            print(f'\n{success}\n')
            print("\nüéâ –°–∫—Ä–∞–ø–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        else:
            print("\n‚ùå –°–∫—Ä–∞–ø–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–∞–º–∏")

    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –°–∫—Ä–∞–ø–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        scraper.cleanup()
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        scraper.cleanup()


if __name__ == "__main__":
    main()
